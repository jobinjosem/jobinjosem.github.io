[ { "title": "Aliases I use in my Bash Shell", "url": "/wsl/2023/09/27/aliases-in-bash.html", "categories": "WSL", "tags": "wsl", "date": "2023-09-27 23:25:37 +0200", "snippet": "Why Use Aliases?I’m constantly immersed in Kubernetes tasks throughout the day. Whether it’s troubleshooting or conducting routine checks, one of the biggest challenges I face is the need to repeat...", "content": "Why Use Aliases?I’m constantly immersed in Kubernetes tasks throughout the day. Whether it’s troubleshooting or conducting routine checks, one of the biggest challenges I face is the need to repeatedly type lengthy commands. It got me thinking about how we can streamline this process and minimize the need for typing out these complex commands over and over again. Sure, creating aliases in the shell is an option, but is there more we can do to enhance usability?That’s when I stumbled upon a fantastic tool called fuzzy finder. Fuzzy finder is an interactive Unix filter for the command-line that can be applied to a wide range of lists, including files, command history, processes, hostnames, bookmarks, git commits, and more. If you’re interested in setting up Bash with ‘oh-my-posh’ and installing ‘fzf,’ I’ve detailed the steps in one of my previous posts.By harnessing the power of ‘fzf,’ we can take our aliases to the next level and seamlessly pass inputs to commands using simple arrow keys or mouse clicks. Below, you’ll find a selection of aliases that I personally use and find incredibly helpful.Kubernetes Aliases Get the yaml formatted output of any resource. Usage: getyaml &lt;resource_type&gt; alias getyaml='function get_k8s_yaml() { kubectl get $1 -o=json | jq -r \".items[].metadata.name\" | fzf --preview \"kubectl get $1 {} -o=yaml\" --preview-window=up:60% | xargs -I {} sh -c \"kubectl get $1 {} -o=yaml | yq .\"; }; get_k8s_yaml' Get the json formatted output of any resource. Usage: getjson &lt;resource_type&gt; alias getjson='function get_k8s_json() { kubectl get $1 -o=json | jq -r \".items[].metadata.name\" | fzf --preview \"kubectl get $1 {} -o=json | jq .\" --preview-window=up:60% | xargs -I {} sh -c \"kubectl get $1 {} -o=json | jq .\"; }; get_k8s_json' Describe the resource Usage: describe &lt;resource_type&gt; alias describe='function describe_k8s_resource() { local resource_type=\"$1\"; kubectl get ${resource_type} -o=json | jq -r \".items[].metadata.name\" | fzf --preview \"kubectl describe ${resource_type} {}\" --preview-window=up:60% | xargs -I {} sh -c \"kubectl describe ${resource_type} {} | tee /dev/tty\"; }; describe_k8s_resource' Get particular field of inputted resource Usage: getfield &lt;resource_type&gt; &lt;field_name&gt; alias getfield='function get_k8s_field() { local k8s_object=\"$1\" local field=\"$2\" local selected_item selected_item=$(kubectl get \"$k8s_object\" -o=json | jq -r \".items[].metadata.name\" | fzf) if [ -n \"$selected_item\" ]; then echo \"$k8s_object: $selected_item\" local field_value field_value=$(kubectl get \"$k8s_object\" \"$selected_item\" -o=json | jq -r \".$field\") echo \"$field: $field_value\" fi}get_k8s_field' Get logs of inputted container Usage: getlogs alias getlogs='selected_pod=$(kubectl get pods --no-headers | fzf --preview-window=up:30%:wrap --header=\"Select a Pod to View Logs\" | awk \"{print \\$1}\"); if [ -n \"$selected_pod\" ]; then selected_container=$(kubectl get pod $selected_pod -o jsonpath=\"{.spec.containers[*].name}\" | tr \" \" \"\\n\" | fzf --preview \"kubectl logs $selected_pod -c {}\" --preview-window=up:30%:wrap --header=\"Select a Container\" | awk \"{print \\$1}\"); if [ -n \"$selected_container\" ]; then kubectl logs $selected_pod -c $selected_container; fi; fi' Show events on a namespace sorted by time. events='kubectl get events --sort-by=.lastTimestamp' Show all resources available in a namespace alias kresources='kubectl api-resources --verbs=list --namespaced -o name | xargs -n 1 kubectl get --show-kind --ignore-not-found' FluxCD Aliases List all Flux sources alias src='flux get source all -A 2&gt;/dev/null' List all Kustomizations alias ks='flux get ks -A 2&gt;/dev/null' List all HelmReleases alias hr='flux get hr -A 2&gt;/dev/null' Kustomization Reconciliation alias ksrec='NAMESPACE_KSNAME=$(flux get ks -A 2&gt;/dev/null | tail -n +2 | grep -v ^$ | awk \"{print \\$1\\\"/\\\"\\$2}\" | fzf); if [[ ! -z $NAMESPACE_KSNAME ]]; then NAMESPACE=$(NAMESPACE_KSNAME | cut -d \"/\" -f 1); KSNAME=$(echo $NAMESPACE_KSNAME | cut -d \"/\" -f 2); flux reconcile kustomization --namespace $NAMESPACE $KSNAME --with-source; fi' HelmRelease Reconciliation alias hrrec='NAMESPACE_HRNAME=$(flux get hr -A 2&gt;/dev/null | tail -n +2 | grep -v ^$ | awk \"{print \\$1\\\"/\\\"\\$2}\" | fzf); if [[ ! -z $NAMESPACE_HRNAME ]]; then NAMESPACE=$(NAMESPACE_HRNAME | cut -d \"/\" -f 1); HRNAME=$(echo $NAMESPACE_HRNAME | cut -d \"/\" -f 2); flux reconcile helmrelease --namespace $NAMESPACE $KSNAME --with-source; fi' Git Source Reconciliation alias srcrecgit='NAMESPACE_SRCNAME=$(flux get source git -A 2&gt;/dev/null | tail -n +2 | grep -v ^$ | awk \"{print \\$1\\\"/\\\"\\$2}\" | fzf); if [[ ! -z $NAMESPACE_SRCNAME ]]; then NAMESPACE=$(NAMESPACE_SRCNAME | cut -d \"/\" -f 1); SRCNAME=$(echo $NAMESPACE_SRCNAME | cut -d \"/\" -f 2); flux reconcile source git --namespace $NAMESPACE $SRCNAME; fi' Helm Source Reconciliation alias srcrechelm='NAMESPACE_SRCNAME=$(flux get source helm -A 2&gt;/dev/null | tail -n +2 | grep -v ^$ | awk \"{print \\$1\\\"/\\\"\\$2}\" | fzf); if [[ ! -z $NAMESPACE_SRCNAME ]]; then NAMESPACE=$(NAMESPACE_SRCNAME | cut -d \"/\" -f 1); SRCNAME=$(echo $NAMESPACE_SRCNAME | cut -d \"/\" -f 2); flux reconcile helmrelease --namespace $NAMESPACE $SRCNAME; fi' Git Aliases Switch between repositories alias repo='cd ~/github/$(ls ~/github | grep ^ | fzf)' Switch between branches alias branch='branch=$(git branch -a | fzf) &amp;&amp; if [[ $branch == *\"origin\"* ]]; then git switch --track $branch; else git switch $branch; fi' " }, { "title": "TechDocs in Backstage", "url": "/technical-writing/backstage/2023/09/01/techdocs-backstage.html", "categories": "technical-writing, backstage", "tags": "backstage, mkdocs", "date": "2023-09-01 00:00:00 +0200", "snippet": "What is TechDocs?TechDocs is Spotify’s in-house solution for documentation-as-code, seamlessly integrated into Backstage. It aligns with the “docs like code” philosophy, where documentation is auth...", "content": "What is TechDocs?TechDocs is Spotify’s in-house solution for documentation-as-code, seamlessly integrated into Backstage. It aligns with the “docs like code” philosophy, where documentation is authored and managed alongside the source code of the underlying software. You write documentation in Markdown files, and with minimal configuration, you can create a beautifully formatted documentation site in Backstage. TechDocs utilizes mkdocs under the hood to build project documentation.Incorporating TechDocs into BackstageThe first step is to add the TechDocs plugin to your Backstage application. You will need to include the @backstage/plugin-techdocs and @backstage/plugin-techdocs-backend packages and make some modifications to the configuration files. Detailed steps are provided in the Backstage documentation.Setting the configurationIn the app-config.yaml file, there are primarily three flags that we configure. For a comprehensive reference, you can find more information here.techdocs: builder: 'local' publisher: type: 'local' generator: runIn: local builder: The value can be either local or external. This flag determines whether the documents should be built locally or not. If set to external, Backstage assumes that the documents will be generated as part of the CI/CD process and readily available in some cloud storage. In that case techdocs-backend will only fetch the docs and will NOT attempt to generate and publish them. publisher: The values can be local or googleGcs or awsS3 or azureBlobStorage. Depending on the value used the Backstage will determine whee to store the generated files. generator: This can be set to either docker or local. It determines how to run the generator, specifically whether to run it using a Docker container or locally. When you run Backstage in Docker, this must be set to ‘local’ to avoid a Docker-in-Docker situation.While the local setup will work to get the setup running quickly, it is not recommended for production usage. If you have a distributed Backstage setup, with multiple pods running in Kubernetes, using local configuration may lead to page duplication or data loss. On the other hand, if you are using cloud storage, you may need to restrict access to the storage and only allow techdocs-backend to fetch files to ensure security.Enable documentation for an entity Create an mkdocs.yml file in the root of your repository with the following content:site_name: 'example-docs'nav: - Home: index.mdplugins: - techdocs-core Update your component’s catalog-info.yaml in the root of its repository:metadata: annotations: backstage.io/techdocs-ref: dir:. If the techdocs source content is in a remote location, you can specify a URL location reference. You can also provide a path to a non-root directory which contains the mkdocs.yml and /docs directory. Create a /docs folder in the root of your repository with at least an index.md file in it. The folder /docs can be renamed to something else if you would like. See mkdocs documentation Commit and merge the changes and you should be able to see the docs in Backstage.Previewing your documentationUsing tech-docs cli you can preview the documentation from your CLI. To do this: Install techdocs-cli npm install -g @techdocs/cli Navigate to the directory where your mkdocs.yaml is located. Run npx @techdocs/cli serve The command starts two local servers - An mkdocs preview server on port 8000 and a Backstage app server on port 3000. Head over to localhost:8000 if you want to browse thorough the mkdocs view.BookmarksTechDocs AddonsTechDocs CLImkdocs-techdocs-coremkdocs-formatting" }, { "title": "Azure Workload Identity on Kubernetes", "url": "/azure/2023/08/24/azure-workload-identity.html", "categories": "Azure", "tags": "azure, kubernetes", "date": "2023-08-24 11:12:22 +0200", "snippet": "Deployed workloads within Kubernetes clusters necessitate Azure AD application credentials or managed identities for accessing Azure AD protected resources, like Azure Key Vault and Microsoft Graph...", "content": "Deployed workloads within Kubernetes clusters necessitate Azure AD application credentials or managed identities for accessing Azure AD protected resources, like Azure Key Vault and Microsoft Graph. Azure AD Pod Identity, previously offered a means to circumvent the requirement for such secrets through the utilization of Azure managed identities.The open source Azure AD pod-managed identity in AKS has been deprecated and the project will be archived soon. Azure AD workload identity replaces pod-managed identity.In contrast, Azure AD Workload Identity for Kubernetes seamlessly incorporates the Kubernetes capabilities to establish federation with external identity providers. This method is much more simpler and removes the complexity of AAD Pod Identities.Authentication Sequence using OIDCCourtesy: microsoft.comHow to deploy and configure AKS clusterMicrosoft Docs - workload-identity-deploy-clusterHow to retrieve the OIDC Issuer URLaz aks show -n myAKSCluster -g \"${RESOURCE_GROUP}\" --query \"oidcIssuerProfile.issuerUrl\" -otsvBy default, the Issuer is set to use the base URL https://{region}.oic.prod-aks.azure.com/{uuid} where the value for {region} matches the location the AKS cluster is deployed in. The value {uuid} represents the OIDC key.OIDC Endpoints {IssuerURL}/.well-known/openid-configuration Also known as the OIDC discovery document. This contains the metadata about the issuer’s configurations. {IssuerURL}/openid/v1/jwks This contains the public signing key(s) that AAD uses to verify the authenticity of the service account token. Create Federated identity credentialaz identity federated-credential create --name ${FEDERATED_IDENTITY_CREDENTIAL_NAME} --identity-name \"${USER_ASSIGNED_IDENTITY_NAME}\" --resource-group \"${RESOURCE_GROUP}\" --issuer \"${AKS_OIDC_ISSUER}\" --subject system:serviceaccount:\"${SERVICE_ACCOUNT_NAMESPACE}\":\"${SERVICE_ACCOUNT_NAME}\" --audience api://AzureADTokenExchangeService Account token mount locationThe azure identity token is mounted at below location by default but this can be changed in the pod manifests./var/run/secrets/azure/tokens/azure-identity-token The regular kubernetes serviceaccount token is mounted at: /var/run/secrets/kubernetes.io/serviceaccountEnvironment Variables AZURE_AUTHORITY_HOST\tThe Azure Active Directory (AAD) endpoint. AZURE_CLIENT_ID\tThe client ID of the AAD application or user-assigned managed identity. AZURE_TENANT_ID\tThe tenant ID of the registered AAD application or user-assigned managed identity. AZURE_FEDERATED_TOKEN_FILE\tThe path of the projected service account token file.Volume injected by the webhook azure-identity-token\tThe projected service account volume. These values can be verified by running kubectl describe pod commandJump pod manifest for verifying Kubernetes service account tokencat &lt;&lt;EOF | kubectl apply -f -apiVersion: v1kind: Podmetadata: name: jump namespace: ${NAMESPACE}spec: containers: - image: smallstep/step-cli name: step-cli command: - /bin/sh - -c - cat /var/run/secrets/tokens/test-token | step crypto jwt inspect --insecure volumeMounts: - mountPath: /var/run/secrets/tokens name: test-token serviceAccountName: ${SERVICE_ACCOUNT_NAME} volumes: - name: test-token projected: sources: - serviceAccountToken: path: test-token expirationSeconds: 3600 audience: testEOFThe jump pod logs will contain the decoded JWT. Note that the values like audience, expirationSeconds etc can be customized in the manifest while the azure-identity-token behaviour can be modified adding custom labels on the pod.Jump pod for verifying access tokenkubectl run az-cli -n default -l \"azure.workload.identity/use=true\" --image=mcr.microsoft.com/azure-cli -i --tty --rm --command /usr/bin/env --overrides='{\"spec\": { \"serviceAccount\": \"workload-identity-sa\" }}' -- shaz login --federated-token \"$(cat $AZURE_FEDERATED_TOKEN_FILE)\" --service-principal -u $AZURE_CLIENT_ID -t $AZURE_TENANT_IDaz account get-access-tokenHow to check the pod is labeledkubectl get pods -A -o json | jq -r '[\"Namespace\", \"Pod-Name\"], (.items[] | select(.metadata.labels.\"azure.workload.identity/use\" == \"true\") | [.metadata.namespace, .metadata.name]) | @tsv' | column -tGet all deployments with the labels onkubectl get deployments --all-namespaces -o json | jq -r '.items[] | select(.spec.template.metadata.labels.\"azure.workload.identity/use\" == \"true\") | \"\\(.metadata.namespace) \\(.metadata.name)\"'Token comparisonDisplayed below are three decoded tokens arranged side by side: the first is a standard service account token, the middle one represents an Azure identity token, and the third corresponds to an Azure access token.Limitations You can only have 20 federated identity credentials per managed identity.BookmarksMicrosoft DocsAzure Workload Identity Gihub PagesDeploy ScriptSample Application" }, { "title": "Unveiling the Construction of This Blog", "url": "/blog/2022/04/12/maintain-static-website.html", "categories": "blog", "tags": "blog", "date": "2022-04-12 21:12:22 +0200", "snippet": "When seeking information, we typically turn to the internet and utilize specific keywords for our search. While numerous blog posts are available, a significant portion of them reiterate the same i...", "content": "When seeking information, we typically turn to the internet and utilize specific keywords for our search. While numerous blog posts are available, a significant portion of them reiterate the same information redundantly. Consequently, when I contemplated creating my own posts, I hesitated to contribute yet another to the pool. Nonetheless, I recognized the value of having a repository to store and easily revisit the knowledge I acquire. Furthermore, by sharing it, others in need of similar information can also reap the benefits. I trust that you’ll discover something valuable within these articles.In this post, I’ll explain how I made my blog and added information to it. I’ve experimented with various tools before, such as Hugo, Jekyll, and Gridsome. Eventually, I settled on Jekyll because I came across a fantastic Jekyll theme called “Chirpy” in the theme gallery. This theme is minimal, responsive, and packed with features specifically designed for technical writing. Also the project is actively maintained. Now, let’s delve into the process of installing Jekyll and configuring the Chirpy theme.Install PrerequisitesJekyll is a Ruby Gem that can be installed on most systems. so you will have to install ruby and some prerequisites apps. This can be done by running the command:sudo apt-get install ruby-full build-essential zlib1g-devAdd ENV variablesThe following commands will add environment variables to your ~/.bashrc file to configure the gem installation path.echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrcecho 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrcecho 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrcsource ~/.bashrcInstall Jekyll and bundlerInstall Jekyll and Bundler using the below command.gem install jekyll bundlerCreating a New SiteSign in to GitHub and browse to Chirpy Starter, click the button Use this template &gt; Create a new repository, and name the new repository USERNAME.github.io, where USERNAME represents your GitHub username. While some suggest creating a public repository as USERNAME.github.io, it’s wise to keep the configuration private and copy only the build output’s contents to the public repository. This ensures you share only what you intend.Installing DependenciesBefore running local server for the first time, go to the root directory of your site and runbundleUpdate ConfigurationUpdate the variables of _config.yml as needed. The file can be found at the root of the repository.Create new postsFor Jekyll to render correctly, the file names must be in certain format and the conent should include some metadata. I use the below script for creating new posts which will create a new file based on user inputs. Later you can edit the new file add your content to it.#!/bin/bash# Get current date, year, and monthDATE=$(date +\"%Y-%m-%d\")YEAR=$(date +\"%Y\")MONTH=$(date +\"%m\")DATEFORPOST=$(date -u '+%Y-%m-%d %H:%M:%S %z')# Get title from user inputecho \"Enter the post title:\"read TITLEecho \"Enter the post slug:\"read SLUG# Create year and month directories if they don't existmkdir -p _posts/$YEAR/$MONTH# Create the file with YAML frontmattercat &gt; _posts/$YEAR/$MONTH/$DATE-$SLUG.md &lt;&lt;EOL---title: \"$TITLE\"date: $DATEFORPOSTcategories:- technical-writing- AItags:- azure- kuberneteskeywords:description: \"\"---EOLRunning Local ServerYou may want to preview the site contents before publishing, so just runbundle exec jekyll sAfter a few seconds, the local service will be published at http://127.0.0.1:4000.Build and DeployGo to the root of the source project, and build your site as follows:JEKYLL_ENV=production bundle exec jekyll bUnless you specified the output path, the generated site files will be placed in folder _site of the project’s root directory. Now you should upload those files to the target server. Commit the changes and push to the github repository.If you prefer to keep your configuration and shareable content separate, then copy the contents of the _site folder to a separate repository named USERNAME.github.io. Although GitHub free accounts require USERNAME.github.io to be public, you can still maintain the configuration repository as private.Create a Github pages SiteGithub has it well documented here at this link. Follow the instructions and publish your siteConfigure Custom DomainIf you would like to add a custom domain, you can do so by following the steps from hereBookmarksChirpy Starter GuideAnother site using Chirpy theme" }, { "title": "WSL Bash customization using oh-my-posh", "url": "/wsl/2022/03/01/oh-my-posh-bash.html", "categories": "WSL", "tags": "wsl, kubernetes", "date": "2022-03-01 10:12:22 +0100", "snippet": "In this post, I will explain how I tweaked my bash prompt in WSL using oh-my-posh. Below are the steps I followed to personalize my bash shell.Install oh-my-posh.sudo wget https://github.com/JanDeD...", "content": "In this post, I will explain how I tweaked my bash prompt in WSL using oh-my-posh. Below are the steps I followed to personalize my bash shell.Install oh-my-posh.sudo wget https://github.com/JanDeDobbeleer/oh-my-posh/releases/latest/download/posh-linux-amd64 -O /usr/local/bin/oh-my-poshsudo chmod +x /usr/local/bin/oh-my-poshInstall a font that supports Powerline symbols. Download the Caskaydia Cove Nerd Font. Extract the zip file, select them all and right-click to install. Set the Caskaydia font on the settings of the windows terminal.Navigate to Windows Terminal –&gt; Settings –&gt; Ubuntu –&gt; Appearance –&gt; Font face. Then choose CaskaydiaCove Nerd Font and click save. Get the custom configuration file.mkdir ~/.poshthemesgit clone https://github.com/jobinjosem/oh-my-posh-custom-theme.git ~/.poshthemesConfigure ~/.bashrcAdd the following to ~/.bashrc (could be ~/.profile or ```` depending on your environment)eval \"$(oh-my-posh --init --shell bash --config '~/.poshthemes/mytheme.omp.json')\"Once added, reload your profile for the changes to take effect by running exec bashI got my prompt looks like this after doing these steps.Install kubectx + kubensThis will help to switch between different kubernetes clusters and namespaces, We need to download the kubectx and kubens binaries and install fuzzyfinderwget -LO kubectx.tar.gz https://github.com/ahmetb/kubectx/releases/download/v0.9.4/kubectx_v0.9.4_linux_x86_64.tar.gztar -xvf kubectx.tar.gzchmod +x kubectxmv kubectx /usr/local/bin/wget -LO kubens.tar.gz https://github.com/ahmetb/kubectx/releases/download/v0.9.4/kubens_v0.9.4_linux_x86_64.tar.gztar -xvf kubens.tar.gzchmod +x kubensmv kubens /usr/local/bingit clone --depth 1 https://github.com/junegunn/fzf.git ~/.fzf~/.fzf/install Check for newer kubectx and kubens releases before downloading..Create aliasTo enhance your ability to seamlessly transition between different clusters and namespaces, it’s a wise approach to establish aliases. Incorporate the following aliases into your .bashrc filealias x='kubectx'alias n='kubens'source ~/.bashrcAfter adding these aliases, you’ll be able to use x to switch between clusters and n to switch between namespaces, making your interaction with Kubernetes more convenient. A list of available Kubernetes cluster contexts in your kubecfg will be shown.Thanks for reading. Please do share your feedback." } ]
